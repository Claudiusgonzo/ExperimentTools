{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hello XTLib Store\n",
    "This notebook serves as an introduction to the concepts and API's of XTLib.\n",
    "\n",
    "Let's get started by importing some libraries that we will need for this notebook, including a few from XTLib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import time\n",
    "import shutil\n",
    "import tempfile\n",
    "import numpy as np\n",
    "\n",
    "# for xtlib internal development, we give preference to our working xtlib sources\n",
    "sys.path.insert(0, os.getcwd() + \"/..\")\n",
    "\n",
    "import xtlib\n",
    "from xtlib.xt_store import XTStore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XTLib Services\n",
    "XTLib has 2 primary services:\n",
    "    - store (where experiments and related files kept)\n",
    "    - compute (used to scale up your ML runs)\n",
    "    \n",
    "In this notebook, we will focus on the **store** service.  T\n",
    "\n",
    "The store that we access thru the service can be either file-based (local machine or server), or Azure-based \n",
    "(based on an Azure storage account).  Here, we will use a file-based store so we don't have to enter \n",
    "the Azure storage name and key. It will also enable a more predictable environment for our notebook.\n",
    "\n",
    "**Note:** the store service API is the same, no matter if the store is file-based or Azure-based."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xtlib.xt_store.XTStore object at 0x00000173B21C56D8>\n"
     ]
    }
   ],
   "source": [
    "# create an azure store\n",
    "# store = XTStore(\"myazurestore\", \"xxxxxxxxxxxxxx\")\n",
    "\n",
    "# create a file-based store\n",
    "dir = \"./temp_localstore_folder\"\n",
    "\n",
    "# ensure we start with a new store folder, so our notebook knows what to expect\n",
    "if os.path.exists(dir):\n",
    "    shutil.rmtree(dir)\n",
    "\n",
    "# if dir doesn't exist, it will be created\n",
    "store = XTStore(dir)\n",
    "\n",
    "console.print(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Concepts\n",
    " Within a store, you will find:\n",
    "        - runs (a run is a single execution of your ML app on a machine)\n",
    "        - experiments (an experiment is a named grouping of your runs)\n",
    "        - workspaces (a workspace can hold multiple experiments and is also the unit of collaboration between users)\n",
    "        - files (files can be associated with workspaces, experiments, and runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# let's start by enumerating the currently defined workspaces\n",
    "\n",
    "ws_list = store.get_workspace_names()\n",
    "console.print(ws_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As we might expect, there are not defined yet in our new store.\n",
    "Let's try some more of the workspace functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result= False\n",
      "result2= True\n"
     ]
    }
   ],
   "source": [
    "ws_name = \"myws\"\n",
    "\n",
    "result = store.does_workspace_exist(ws_name)\n",
    "console.print(\"result=\", result)\n",
    "\n",
    "if result:\n",
    "    store.delete_workspace(ws_name)\n",
    "    \n",
    "store.create_workspace(ws_name)\n",
    "\n",
    "result2 = store.does_workspace_exist(ws_name)\n",
    "console.print(\"result2=\", result2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments and Runs\n",
    "There is currently no XTLib API for explictly managing experiment names (groups names for runs), but we can use experiment names as we create runs.  Let's see what that looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the run entity (think of this a logging the beginning of an ML training run)\n",
    "exper_name = \"my first experiment\"\n",
    "run_name = store.start_run(ws_name, exper_name)\n",
    "\n",
    "run_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OK, that seemed to work.\n",
    "Typically, an ML app would log values of hyperparameters and metrics during the run.  Let's simulate an ML app\n",
    "and do the logging, including the call to end_run()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "epoch 10\n",
      "epoch 20\n",
      "end of our run.\n"
     ]
    }
   ],
   "source": [
    "# log hyperparameters used for this run\n",
    "lr = .01\n",
    "epochs = 30\n",
    "store.log_run_event(ws_name, run_name, \"hp\", {\"lr\": lr, \"epochs\": epochs})\n",
    "                                                     \n",
    "# simulate some training                                                    \n",
    "for epoch in range(epochs):\n",
    "    time.sleep(.1)   \n",
    "                                                      \n",
    "    if epoch % 10 == 0:\n",
    "                                                      \n",
    "        console.print(\"epoch\", epoch)\n",
    "        val_loss = .5*np.random.random()\n",
    "        val_acc = .5 + .5*np.random.random()\n",
    "        \n",
    "        # we can log hp/metrics one or multiple name/value pairs within a single call\n",
    "        store.log_run_event(ws_name, run_name, \"metrics\", {\"val_loss\": val_loss})\n",
    "        store.log_run_event(ws_name, run_name, \"metrics\", {\"val_acc\": val_acc})\n",
    "        \n",
    "# simulate end of training run\n",
    "rollups = {\"val_loss\": val_loss, \"val_acc\": val_acc}\n",
    "store.end_run(ws_name, run_name, status=\"completed\", exit_code=0, metrics_rollup_dict=rollups)\n",
    "                                                      \n",
    "console.print(\"end of our run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, we have a completed run entity\n",
    "If we were using a tool like XT to launch our ML apps, it would capture certain files for us.\n",
    "These can be grouped into BEFORE files (those that existed in our working directory before the run) and\n",
    "AFTER files, a snapshot of the files in the working directory after the run completes.\n",
    "\n",
    "## Let's upload these types of files to our store from our code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a source file\n",
    "fn_source = \"myapp.py\"\n",
    "with open(fn_source, \"w\") as tfile:\n",
    "    tfile.write(\"import sys\\nprint('hello world')\\n\")\n",
    "\n",
    "# create a console output file\n",
    "fn_console = \"console.txt\"\n",
    "with open(fn_console, \"w\") as tfile:\n",
    "    tfile.write(\"hello world\\n\")\n",
    "\n",
    "# upload source file to BEFORE/AFTER dirs of run\n",
    "store.upload_file_to_run(ws_name, run_name, \"before/\" + fn_source, fn_source)\n",
    "store.upload_file_to_run(ws_name, run_name, \"after/\" + fn_source, fn_source)\n",
    "\n",
    "# upload console file to AFTER dir of run\n",
    "store.upload_file_to_run(ws_name, run_name, \"after/\" + fn_console, fn_console)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last step of Notebook\n",
    "As a last stop, we recommend that you examine the file-based store that was created in this notebook.  This can be done using the Jupyter Console tab in your browser (where you located and opened this notebook) - look for the directory:\n",
    "\n",
    "    - temp_localstore_folder\n",
    "    \n",
    "If you happened to change this to work with your Azure account, you can use Azure Storage Explorer or the Azure portal to examine the container created for your workspace and the blobs for the files within the workspace.\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (EXPER)",
   "language": "python",
   "name": "exper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
