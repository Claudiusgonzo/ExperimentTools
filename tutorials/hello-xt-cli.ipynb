{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XT command line tool\n",
    "In this notebook, we will introduce the XT command line tool.  \n",
    "\n",
    "We will run XT commands and examine their output using Jupyter Notebooks \"!\" (bang) command, which runs the command that follows the \"!\" as a shell command.  This should work on both Windows and Linux.\n",
    "\n",
    "IMPORTANT: when running XT on a normal Windows or Linux command line, do NOT include the \"!\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start simple.\n",
    "\n",
    "running \"xt\" without any commands will give us an about-style help display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XTlib (v.1, build Apr-3-2019)\n",
      "Experiment Tools Library\n",
      "\n",
      "XTlib is an API and command line tool for running and managing ML experiments.  \n",
      "\n",
      "Features:\n",
      "    - Experiment Store (local machine, server, Azure Storage)\n",
      "        - centralized storage of experiment logs, source files, results, and models\n",
      "        - management of workspaces (add ws, add collaborators, delete ws, enumerate)\n",
      "        - management of experiments (add, annotate, delete, copy, extract, enumerate)\n",
      "        - management of workspace and experiment files (upload, download, enumerate)\n",
      "\n",
      "    - Experiment Run (local machine, server, Azure VM, Azure Batch)\n",
      "        - start new experiment on specified machine(s)\n",
      "        - stop run\n",
      "        - check / monitor status of run\n",
      "        - annotate run (comments)\n",
      "        - log events\n",
      "        - hyperparameter tuning runs\n",
      "\n",
      "The goal of XTLib is to enable you to effortlessly organize and scale your ML experiments.\n",
      "Our tools offer an incremental approach to adoption, so you can begin realizing benifits immediatly.\n",
      "\n",
      "XTLib provides an experiment STORE that enables you to easily track, compare, rerun, and share your ML experiments.  \n",
      "The STORE consists of user-defined workspaces, each of which can contain a set of user-run experiments.  \n",
      "XT currently supports 2 STORE services: local (folder-based) and azure (Azure Storage-based).\n",
      "\n",
      "In addition, XTLb also provides simple access to scalable COMPUTE resources so you can \n",
      "easily run multiple experiments in parallel and on larger computers, as needed.  With this feature, \n",
      "you can run your experiments on your local machine, other local computers or provised VMs to which you \n",
      "have aceess, or on 1 or more cloud computers, allocated on demand (Azure Batch).\n",
      "\n",
      "Finally, XTLib offers a few other experiment-related features to help maximize your ML agility:\n",
      "    - hyperparameter searching\n",
      "    - ML code generation for various datasets and models \n",
      "\n",
      "For more information, run: xt --help\n"
     ]
    }
   ],
   "source": [
    "!xt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"xt --help\" will give us command help.\n",
    "\n",
    "Note that the dimmed text is for the commands not yet implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[106;0;1musage: XT <options> <command>\n",
      "\u001b[106;0;0m\u001b[106;0;1mnote: BOLD commands are implemented and ready for testing.\n",
      "\u001b[106;0;0m\n",
      "general:\n",
      "\u001b[106;0;1m    - xt                   # display XT about information\n",
      "\u001b[106;0;0m\u001b[106;0;1m    - xt config            # edit/view the config file settings\n",
      "\u001b[106;0;0m\u001b[106;0;1m    - xt help [ <value> ]  # displays XR commands and options (value can be 'cmds', 'about', or 'api')\n",
      "\u001b[106;0;0m\n",
      "experiments:\n",
      "\u001b[106;0;1m    - xt python file <app args>                # run python on file (with experiment logging, capture, and scraping)\n",
      "\u001b[106;0;0m\u001b[106;0;1m    - xt run app <app args>                    # run the app (with experiment logging and capture)\n",
      "\u001b[106;0;0m\u001b[106;0;1m    - xt list experiments [ <name> ]           # list all (or matching) experiments in current workspace\n",
      "\u001b[106;0;0m    - xt delete experiment <name>              # delete the specified experiment\n",
      "    - xt copy experiment <name> to <ws name>   # copy experiment to another workspace\n",
      "\u001b[106;0;1m    - xt extract <name> to <output directory>  # copy the specified experiment from the store to a local directory\n",
      "\u001b[106;0;0m    - xt rerun <name> [ <app args> ]           # rerun the specified experiment with optional new cmd args\n",
      "    - xt monitor [ <name> ]                    # monitor all (or specified) running experiments\n",
      "\u001b[106;0;1m    - xt attach <name>                         # attach output of experiment to console (use ESC to detach)\n",
      "\u001b[106;0;0m\u001b[106;0;1m    - xt status                                # display the selected STORE and current workspace\n",
      "\u001b[106;0;0m\n",
      "workspaces:\n",
      "\u001b[106;0;1m    - xt list workspaces                   # list workspaces \n",
      "\u001b[106;0;0m\u001b[106;0;1m    - xt create workspace <name            # create new workspace\n",
      "\u001b[106;0;0m    - xt delete workspace <name>           # delete the specified workspace\n",
      "    - xt share <ws name> with <username>   # share the specified workspace with another user\n",
      "\n",
      "code generation:\n",
      "    - xt list datasets                     # list supported datasets\n",
      "    - xt list models                       # list supported models\n",
      "    - xt generate <dataset> <model> to <output file>   # gen code to train specified dataset/model combo\n",
      "\n",
      "general options:  (mostly override config settings)\n",
      "\u001b[106;0;1m    --help                          # console.print detailed help\n",
      "\u001b[106;0;0m\u001b[106;0;1m    --log <bool>                    # override logging experiment to STORE \n",
      "\u001b[106;0;0m\u001b[106;0;1m    --capture <value>               # override capturing files for this experiment (none, before, after, all)\n",
      "\u001b[106;0;0m\u001b[106;0;1m    --console.print <value>                 # override when to console.print experiment name (none, before, after, all)\n",
      "\u001b[106;0;0m\u001b[106;0;1m    --notes <value>                 # override when to prompt user for notes (none, before, after, all)\n",
      "\u001b[106;0;0m    --scrape <bool>                 # override scrape of stdout for progress and final metric \n",
      "    --ws <name>                     # override the default workspace name \n",
      "\u001b[106;0;1m    --exper <name>                  # specifies the experiment name \n",
      "\u001b[106;0;0m\u001b[106;0;1m    --compute <name>                # run experiment on specified computer(s) (azure, local, or config file named box)\n",
      "\u001b[106;0;0m\u001b[106;0;1m    --hold                          # after experiment has completed, holds the allocated computer open for debugging\n",
      "\u001b[106;0;0m    --vm-size=<name>                # override specified azure machine type \n",
      "    --hp=<number>                   # hyperparm search on arg values in [], for specified # of searches \n",
      "    --tags=<quoted string of tags>  # add specifed tags to experiment\n",
      "    --fw=<name>                     # override the preferred framework for code generation\n",
      "\n",
      "list command options:\n",
      "    --active                        # only list in-progress experiments\n",
      "    --completed                     # only list completed experiments\n",
      "    --succeeded                     # only list experiments that completed without error\n",
      "    --failed                        # only list experiments that completed with an error\n",
      "    --head [ =<number> ]            # limit items shown to the first N\n",
      "    --tail [ =<number> ]            # limit items shown to the last N\n",
      "\u001b[106;0;1m    --sort <col name>               # default column sort for experiment list\n",
      "\u001b[106;0;0m\u001b[106;0;1m    --reverse <bool>                # if experiment sort should be reversed in order\n",
      "\u001b[106;0;0m\n"
     ]
    }
   ],
   "source": [
    "!xt --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The first command: xt config\n",
    "\n",
    "The first command you need to know about is \"xt config\".  This enables you to view or edit your XT configuration file.  \n",
    "\n",
    "The XT configuration file controls various aspects of XT, including:\n",
    "    - the type of store (file-based or Azure)\n",
    "    - if using a file-based store, the location of the store in your file system\n",
    "    - if using an Azure-based store, the storage service name and key\n",
    "    - the resources for scaling your ML compute\n",
    "    - how to display experiments (columns, format, etc.)\n",
    "    \n",
    "\"xt config\" works by invoking a text editor on the xt config file.  The settings are represented in an .INI type language called TOML.  Before invoking a text editor, the command displays the location of your config file.  If needed, you can always explictly invoke your selected editor to open/edit the file.  \n",
    "\n",
    "Whenever XT is run, it loads the latest version of the config file, so any changes you make to the file will be used the next time XT is run on your local machine.  \n",
    "\n",
    "NOTE: each machine you run XT on has its own separate copy of the configuaration file.\n",
    "\n",
    "For this notebook, the 2 most important settings are located in the [core] section of the file:\n",
    "```\n",
    "   - store         # set this to \"local\" (tells XT to use a file-based store for experiments and runs)\n",
    "   - local_store   # this is the location where the file-based store will be created (change if desired)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XT config file not found; creating it from default settings...\n",
      "invoking your default .toml editor on: C:/Users/rfernand2/.xt/xt_config.toml\n"
     ]
    }
   ],
   "source": [
    "!xt config"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Here is what your editor would show (shown here with default settings):\n",
    "\n",
    "# config.toml: configuration file for XT \n",
    "\n",
    "    [azure]\n",
    "    # use the Azure portal (https://azure.microsoft.com/en-us/features/azure-portal/, use your Microsoft login/alias):\n",
    "    #   - to create a batch service instance for XT to use\n",
    "    #   - to create a storage service instance for XT to use\n",
    "    #   - to create a container within the storage for XT to use\n",
    "    #   - to fill in the 6 values below\n",
    "\n",
    "    # batch service for XT  (Azure portal: select the batch instance, select the \"keys\" vertical tab)\n",
    "    batch_name = \"xxxxx\"\n",
    "    batch_key = \"xxxxxx\"\n",
    "    batch_url = \"xxxxxx\"\n",
    "\n",
    "    # storage service for XT     (Azure portal: select the storage instance, select the \"keys\" vertical tab)\n",
    "    storage_name = \"xxxxxxx\"\n",
    "    storage_key = \"xxxxxxx\"\n",
    "\n",
    "    # Azure batch options\n",
    "    vm_size = \"Standard_NC6\"            # type of computer to use.  \"Standard_NC6\" is a good GPU option to start with.\n",
    "    vm_image_sku = \"dsvm\"               # currently, Azure Data Science VM (Ubuntu) is only option XT supports\n",
    "\n",
    "    [core]\n",
    "    store = \"local\"                             # use \"local\" for FILE-based STORE, \"azure\" for Azure storage based STORE\n",
    "    compute = \"local\"                           # where to run job (local, azure, or a named box from [box-names])\n",
    "    local_store = \"${HOME}/.xt/xt_store\"        # the local/shared directory for FILE-based STORE\n",
    "    ws = \"ws1\"                                  # name of current workspace \n",
    "    input_files_list = [\"**\"]                   # specifies input files (for capture to STORE and deployment to compute nodes)\n",
    "    output_files_list = [\"*\"]                   # specifies output files (for capture from compute node to STORE)\n",
    "    log = true                                  # control if experiments are logged to STORE\n",
    "    capture = \"all\"                             # control which files of experiment are captured (none, before, after, all)\n",
    "    scrape = true                               # control if stdout is scraped for progress and final stats\n",
    "\n",
    "    [general]\n",
    "    notes = \"none\"            # control when user is prompted for notes (none, before, after, all)\n",
    "    console.print = \"all\"             # control when experiment name is printed (none, before, after, all)\n",
    "    fw = \"pytorch\"            # XT will try to use this framework when generating code\n",
    "    sort = \"name\"             # default column sort for experiment list (name, value, status, duration)\n",
    "    reverse = false           # if experiment sort should be reversed in order     \n",
    "    show_log_calls = false    # should logging calls (in STDOUT) be shown?\n",
    "\n",
    "    # cols to show for \"list exper\" cmd     \n",
    "    list_exper_cols = [\"name\", \"app\", \"status\", \"dev-em\", \"dev-f1\", \"dev-loss\", \"epoch\", \"epochs\", \"lr\", \"box\", \"started\", \"duration\"]\n",
    "\n",
    "    [metric_rollups]\n",
    "    # you can edit this to reflect how to roll-up a metric for a run.  \n",
    "    # values should be one of: min, max, last, mean\n",
    "    dev-acc = \"max\"\n",
    "    dev-em = \"max\"\n",
    "    dev-f1 = \"max\"\n",
    "    dev-loss = \"min\"\n",
    "    dev-error = \"min\"\n",
    "\n",
    "    test-acc = \"max\"\n",
    "    test-error = \"min\"\n",
    "\n",
    "    [column_formatting]    \n",
    "    # the cols to display for 'list exper' command (taken from [std_columns] section below)\n",
    "    __default__ = {name=\"__upper__\", hdr_fmt=\">10.10s\", row_fmt=\">10.10s\"}\n",
    "\n",
    "    name = {hdr=\"NAME\", hdr_fmt=\"8.8s\", row_fmt=\"8.8s\"}\n",
    "    box = {hdr=\"BOX\", hdr_fmt=\"16.16s\", row_fmt=\"16.16s\"}\n",
    "    status = {hdr=\"STATUS\", hdr_fmt=\"10.10s\", row_fmt=\"10.10s\"}\n",
    "    exit_code = {hdr=\"EXIT\", hdr_fmt=\">5.5\", row_fmt=\">5.5s\"}\n",
    "    started = {hdr=\"STARTED\", hdr_fmt=\"20.20s\", row_fmt=\"20.20s\"}\n",
    "    duration = {hdr=\"DURATION\", hdr_fmt=\">10.10s\", row_fmt=\">10.10s\"}\n",
    "    app = {hdr=\"APP\", hdr_fmt=\"10.10s\", row_fmt=\"10.10s\"}\n",
    "\n",
    "    # metrics\n",
    "    dev-acc = {hdr=\"TST-ACC\", hdr_fmt=\">8.8s\", row_fmt=\">8.4f\"}\n",
    "    dev-em = {hdr=\"TST-EM\", hdr_fmt=\">8.8s\", row_fmt=\">8.4f\"}\n",
    "    dev-f1 = {hdr=\"TST-F1\", hdr_fmt=\">8.8s\", row_fmt=\">8.2f\"}\n",
    "    dev-loss = {hdr=\"TST-LOSS\", hdr_fmt=\">8.8s\", row_fmt=\">8.2f\"}\n",
    "    dev-error = {hdr=\"TST-ERR\", hdr_fmt=\">8.8s\", row_fmt=\">8.4f\"}\n",
    "    epoch = {hdr=\"EPOCH\", hdr_fmt=\">6.6s\", row_fmt=\">6d\"}\n",
    "\n",
    "    test-acc = {hdr=\"TEST-ACC\", hdr_fmt=\">8.8s\", row_fmt=\">8.4f\"}\n",
    "    test-err = {hdr=\"TEST-ERR\", hdr_fmt=\">8.8s\", row_fmt=\">8.4f\"}\n",
    "\n",
    "    # hyperparameters\n",
    "    epochs = {hdr=\"EPOCHS\", hdr_fmt=\">6.6s\", row_fmt=\">6d\"}\n",
    "    lr = {hdr=\"LR\", hdr_fmt=\">7.7s\", row_fmt=\">7.7s\"}\n",
    "    log_interval = {display=false}\n",
    "\n",
    "     [box_names]\n",
    "    # these box names allow you to use a friendlier, shorter name for the XT \"--box=\" option\n",
    "    # here are some examples - replace these with your own shared ML boxes and Azure provisioned VM's\n",
    "    # they will need to have port 22 open for incoming messages to work with XT\n",
    "    bobs_1080ti = \"myusername@121.32.32.21\"\n",
    "    marys_rtx2080 = \"myusername@121.32.32.21\"\n",
    "    my_pool = \"bobs_1080ti, marys_rts2080\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we are ready to try some basic commands.  \n",
    "\n",
    "It is often helpful to confirm which store and workspace you are using.  This can be done with the \"xt status\" command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local://ws1\n"
     ]
    }
   ],
   "source": [
    "!xt status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows that we are using an local (file-based) store and our current workspace is \"ws1\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here's the fun part - our first run\n",
    "\n",
    "Let's run an ML experiment with XT.  The following command instructs XT to run the \"stdoutPytorchMnist.py\" script (which is a slightly modified version of the PyTorch MNIST tutorial).  \n",
    "\n",
    "In XT, an experiment is a grouping of multiple runs. On this command, we have specified that the experiment for this run is \"tutorial-runs\".  Since this experiment name has not yet been defined for the current workspace, it will be created on the fly.  \n",
    "\n",
    "NOTE: due to the buffering used in Jupyter Notebook, this next step may not display any response for 1-2 minutes.  When run from a normal command line, the output will be more incremental."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Experiment local://ws1/tutorial-runs/run3\n",
      "\n",
      "LOCAL: running cmd: ['python', '-u', 'stdoutPytorchMnist.py', '--epochs=2']\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.300039\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.438239\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.368285\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.326093\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.226492\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.340002\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.063720\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.114980\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.145882\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.115922\n",
      "\n",
      "Test set: Average loss: 0.1019, Accuracy: 9657/10000 (97%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.143058\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.100706\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.058106\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.065295\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.118160\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.034130\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.034242\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.037972\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.028487\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.038390\n",
      "\n",
      "Test set: Average loss: 0.0606, Accuracy: 9833/10000 (98%)\n",
      "\n",
      "\n",
      "End Experiment local://ws1/tutorial-runs/run3\n"
     ]
    }
   ],
   "source": [
    "!xt --exper=tutorial-runs python stdoutPytorchMnist.py --epochs=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our second run\n",
    "\n",
    "It looks like that ran successfully (at least when I ran it on my machine - hopefully your live notebook has similiar resuts).  \n",
    "\n",
    "My machine's output shows a final test accuracy of .9828 (9828/10000).\n",
    "\n",
    "Let's try a second run, this time setting the learning rate (lr) to .05:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Experiment local://ws1/tutorial-runs/run4\n",
      "\n",
      "LOCAL: running cmd: ['python', '-u', 'stdoutPytorchMnist.py', '--epochs=2', '--lr=.05']\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.300039\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.125841\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.159618\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.106685\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.108497\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.104471\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.031213\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.113312\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.017529\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.140113\n",
      "\n",
      "Test set: Average loss: 0.0421, Accuracy: 9864/10000 (99%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.012853\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.036424\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.019634\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.007910\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.025989\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.005202\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.004726\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.020420\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.007697\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.007992\n",
      "\n",
      "Test set: Average loss: 0.0316, Accuracy: 9904/10000 (99%)\n",
      "\n",
      "\n",
      "End Experiment local://ws1/tutorial-runs/run4\n"
     ]
    }
   ],
   "source": [
    "!xt --exper=tutorial-runs python stdoutPytorchMnist.py --epochs=2 --lr=.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Results\n",
    "\n",
    "Which run had the best results?\n",
    "\n",
    "Let's list the experiments in our workspace to see the results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local://ws1 experiments:\n",
      "\n",
      "tutorial-runs:\n",
      "--------------\n",
      "\n",
      "  NAME      APP         STATUS      TEST-ACC  TST-LOSS   EPOCH  EPOCHS       LR  BOX                 DURATION  \n",
      "\n",
      "  run1      stdoutPyto  completed     0.9829    0.0606       2       2     0.01  AGENT1               0:00:25  \n",
      "  run2      stdoutPyto  completed     0.9901    0.0304       2       2     0.05  AGENT1               0:00:25  \n",
      "  run3      stdoutPyto  completed     0.9833    0.0606       2       2     0.01  AGENT1               0:00:25  \n",
      "  run4      stdoutPyto  completed     0.9904    0.0316       2       2     0.05  AGENT1               0:00:25  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!xt list exper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to explore\n",
    "\n",
    "That's the end of this notebook. Its time to explore on your own.  \n",
    "\n",
    "Here are our suggested next steps:\n",
    "\n",
    "    - create and activate a virtual environment to test out xtlib:\n",
    "            - conda create -n xtlib-fun python=36\n",
    "            - conda activate xtlib-fun\n",
    "            \n",
    "    - install xtlib:\n",
    "            - pip install xtlib\n",
    "    \n",
    "    - try some xt commands at the command prompt:\n",
    "            - xt status\n",
    "            - xt config\n",
    "            \n",
    "     - use xt to run some of your own ML experiments.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (EXPER)",
   "language": "python",
   "name": "exper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
